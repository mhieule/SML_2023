{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-LN3TVggTrt"
   },
   "source": [
    "# Exercise 3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ala4YaNmKPtb"
   },
   "source": [
    "## Linear Dimensionality Reduction\n",
    "\n",
    "In this task, we will visualize the main principle axes of the IRIS dataset. The dataset contains 150 datapoints of different irises' petal types (Setosa, Versicolour, and Virginica) which are characterized by the *sepal length, sepal width, petal length, and the petal width*. The task can also be thought of as projecting the high-dimensional dataset into lower dimensions (2D in our case) while retaining most of data information, for data exploratory purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffl1-KjCgaWG"
   },
   "source": [
    "### Exercise 3.4.1\n",
    "\n",
    "Implement the Principle Component Analysis (PCA) class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dUUqWBM7Ql0s"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class PCA:\n",
    "  '''\n",
    "  This class computes the first n eigenvectors from the dataset via fit(), and \n",
    "  projects the original data to the subspace spanned by its eigenvectors via \n",
    "  transform().\n",
    "  '''\n",
    "  def __init__(self, n_components):\n",
    "    '''      \n",
    "    Args:\n",
    "        n_components (int): number of principle components. n_components <= d\n",
    "    '''\n",
    "    self.n_components = n_components\n",
    "    self.components = None  # expected size [n_components, d] \n",
    "    self.mean = None  # expected size [d]\n",
    "\n",
    "  def fit(self, X):\n",
    "    '''\n",
    "    Compute the first n_components of eigenvectors from data, and store them\n",
    "    in self.components.\n",
    "    \n",
    "    Args:\n",
    "        X: Array of m points (m, d).\n",
    "    '''\n",
    "    # TODO: Your code here\n",
    "\n",
    "  def transform(self, X):\n",
    "    '''\n",
    "    Project the data into the n_components of eigenvectors.\n",
    "    \n",
    "    Args:\n",
    "        X: Array of m points (m, d).\n",
    "\n",
    "    Returns:\n",
    "        X_projected: X: Array of m points (m, n_components).\n",
    "    '''\n",
    "    # TODO: Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5mrmlzcN9PP"
   },
   "source": [
    "### Exercise 3.4.2\n",
    "Use the PCA class to visualize the IRIS dataset in the first two principle components. The data points are also needed to be colored according to their distinct classes. Are the classes separable with linear discriminators?\n",
    "\n",
    "**Hint:** Use `plt.scatter` to plot the projected data points with colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8II6ILpoNzjJ"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "data = datasets.load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Project the data onto the 2 primary principal components\n",
    "# TODO: Your code here\n",
    "\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of transformed X:\", X_projected.shape)\n",
    "\n",
    "# visualize the projected data\n",
    "# TODO: Your code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
